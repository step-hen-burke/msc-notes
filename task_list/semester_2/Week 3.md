RO draft:



- Identify and compare current approaches to deep neural network compression, taking note of the impact of different network architectures on the applicability and effectiveness of approaches.
- Interview industry experts in order to identify typical scenarios within which a deep neural network would be subject to resource constraints, acceptable performance/resource trade-offs, and typical speed and footprint benchmarks that a compressed model should be evaluated against.
- Using standard datasets (MNIST, CIFAR, Treebank, etc.), evaluate the effectiveness of compression techniques in terms of: disk size reduction, memory usage, predictive performance preserved, inference speed, etc. - particularly with regard to meeting "useful" consumer hardware benchmarks.
- Identify techniques to identify important and unimportant substructures within networks for the purposes of pruning, and evaluate the performance of models with unimportant substructures removed.
- Create compressed predictive models for use in resource-constrained environments using combinations of previously identified techniques which is deemed to be optimal.

Research Domain - Machine Learning (Deep Learning).
Problem Domain - Deploying deep neural networks in resource-constrained environments.

