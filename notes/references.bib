@article{aliHeartDiseasePrediction2021,
  title = {Heart Disease Prediction Using Supervised Machine Learning Algorithms: {{Performance}} Analysis and Comparison},
  shorttitle = {Heart Disease Prediction Using Supervised Machine Learning Algorithms},
  author = {Ali, Md Mamun and Paul, Bikash Kumar and Ahmed, Kawsar and Bui, Francis M. and Quinn, Julian M.W. and Moni, Mohammad Ali},
  year = {2021},
  month = sep,
  journal = {Computers in Biology and Medicine},
  volume = {136},
  pages = {104672},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2021.104672},
  urldate = {2023-09-20},
  langid = {english},
  file = {/home/stephen/Zotero/storage/CSG4QWE8/Ali et al. - 2021 - Heart disease prediction using supervised machine .pdf},
  keywords = {MachineLearning,SupervisedLearning}
}

@book{burgerIntroductionMachineLearning2018,
  title = {Introduction to Machine Learning with {{R}}: Rigorous Mathematical Analysis},
  shorttitle = {Introduction to Machine Learning with {{R}}},
  author = {Burger, Scott V.},
  year = {2018},
  edition = {First edition},
  publisher = {{O'Reilly}},
  address = {{Beijing Boston Farnham Sebastopol Tokyo}},
  abstract = {Machine learning can be a difficult subject if you're not familiar with the basics. With this book, you'll get a solid foundation of introductory principles used in machine learning with the statistical programming language R. You'll start with the basics like regression, then move into more advanced topics like neural networks, and finally delve into the frontier of machine learning in the R world with packages like Caret. By developing a familiarity with topics like understanding the difference between regression and classification models, you'll be able to solve an array of machine learning problems. Knowing when to use a specific model or not can mean the difference between a highly accurate model and a completely useless one. This book provides copious examples to build a working knowledge of machine learning. Understand the major parts of machine learning algorithms Recognize how machine learning can be used to solve a problem in a simple manner Figure out when to use certain machine learning algorithms versus others Learn how to operationalize algorithms with cutting edge packages},
  isbn = {978-1-4919-7644-9},
  langid = {english},
  file = {/home/stephen/Zotero/storage/9B2CTQJF/Scott V. Burger - Introduction to Machine Learning with R. Rigorous Mathematical Analysis-O’Reilly (2018).pdf;/home/stephen/Zotero/storage/X2QPID99/Burger - 2018 - Introduction to machine learning with R rigorous .pdf}
}

@book{dangetiStatisticsMachineLearning2017,
  title = {Statistics for Machine Learning: Techniques for Exploring Supervised, Unsupervised, and Reinforcement Learning Models with {{Python}} and {{R}}},
  shorttitle = {Statistics for Machine Learning},
  author = {Dangeti, Pratap},
  year = {2017},
  publisher = {{Packt Publishing}},
  address = {{Birmingham, UK}},
  isbn = {978-1-78829-575-8},
  langid = {english},
  file = {/home/stephen/Zotero/storage/ABA8TNW4/Dangeti - 2017 - Statistics for machine learning techniques for ex.pdf}
}

@book{downeyThinkStats2012,
  title = {Think Stats},
  author = {Downey, Allen B.},
  year = {2012},
  series = {Probability and Statistics for Programmers},
  edition = {1. ed., 4. release},
  publisher = {{O'Reilly}},
  address = {{Beijing}},
  isbn = {978-1-4493-0711-0},
  langid = {english},
  file = {/home/stephen/Zotero/storage/J8WTXV5R/Downey - 2012 - Think stats.pdf}
}

@book{geronHandsonMachineLearning2019,
  title = {Hands-on Machine Learning with {{Scikit-Learn}}, {{Keras}}, and {{TensorFlow}}: Concepts, Tools, and Techniques to Build Intelligent Systems},
  shorttitle = {Hands-on Machine Learning with {{Scikit-Learn}}, {{Keras}}, and {{TensorFlow}}},
  author = {G{\'e}ron, Aur{\'e}lien},
  year = {2019},
  edition = {Second edition},
  publisher = {{O'Reilly Media, Inc}},
  address = {{Beijing [China] ; Sebastopol, CA}},
  isbn = {978-1-4920-3264-9},
  lccn = {QA76.73.P98 G45 2019},
  file = {/home/stephen/Zotero/storage/E8USP4M9/Géron - 2019 - Hands-on machine learning with Scikit-Learn, Keras.pdf},
  keywords = {ArtificialIntelligence,MachineLearning,Python(ComputerProgramLanguage),TensorFlow}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  series = {Springer {{Texts}} in {{Statistics}}},
  volume = {103},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-7138-7},
  urldate = {2023-09-20},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  file = {/home/stephen/Zotero/storage/GZYJ4IKC/(Springer Texts in Statistics) Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani - An Introduction to Statistical Learning with Applications in R-Springer (2014).pdf;/home/stephen/Zotero/storage/IBSYJFME/James et al. - 2013 - An Introduction to Statistical Learning.pdf}
}

@article{koumarelasDataPreparationDuplicate2020,
  title = {Data {{Preparation}} for {{Duplicate Detection}}},
  author = {Koumarelas, Ioannis and Jiang, Lan and Naumann, Felix},
  year = {2020},
  month = sep,
  journal = {Journal of Data and Information Quality},
  volume = {12},
  number = {3},
  pages = {1--24},
  issn = {1936-1955, 1936-1963},
  doi = {10.1145/3377878},
  urldate = {2023-09-20},
  abstract = {Data errors represent a major issue in most application workflows. Before any important task can take place, a certain data quality has to be guaranteed by eliminating a number of different errors that may appear in data. Typically, most of these errors are fixed with data preparation methods, such as whitespace removal. However, the particular error of duplicate records, where multiple records refer to the same entity, is usually eliminated independently with specialized techniques. Our work is the first to bring these two areas together by applying data preparation operations under a systematic approach prior to performing duplicate detection.             Our process workflow can be summarized as follows: It begins with the user providing as input a sample of the gold standard, the actual dataset, and optionally some constraints to domain-specific data preparations, such as address normalization. The preparation selection operates in two consecutive phases. First, to vastly reduce the search space of ineffective data preparations, decisions are made based on the improvement or worsening of pair similarities. Second, using the remaining data preparations an iterative leave-one-out classification process removes preparations one by one and determines the redundant preparations based on the achieved area under the precision-recall curve (AUC-PR). Using this workflow, we manage to improve the results of duplicate detection up to 19\% in AUC-PR.},
  langid = {english},
  file = {/home/stephen/Zotero/storage/2Q24ST9L/Koumarelas et al. - 2020 - Data Preparation for Duplicate Detection.pdf},
  keywords = {DataCleaning,EDA}
}

@book{laroseDiscoveringKnowledgeData2005,
  title = {Discovering Knowledge in Data: An Introduction to Data Mining},
  shorttitle = {Discovering Knowledge in Data},
  author = {Larose, Daniel T.},
  year = {2005},
  publisher = {{Wiley-Interscience}},
  address = {{Hoboken, NJ}},
  isbn = {978-0-471-66657-8},
  langid = {english},
  file = {/home/stephen/Zotero/storage/699LC4WH/(Wiley Series on Methods and Applications in Data Mining) Daniel T. Larose, Chantel D. Larose - Discovering Knowledge in data An Introduction to Data Mining-Wiley ( 2014).pdf;/home/stephen/Zotero/storage/6MN277H8/Larose - 2005 - Discovering knowledge in data an introduction to .pdf}
}

@article{liBayesianApproachEstimating2009,
  title = {A {{Bayesian Approach}} for {{Estimating}} and {{Replacing Missing Categorical Data}}},
  author = {Li, Xiaobai},
  year = {2009},
  journal = {ACM J. Data Inf. Qual.},
  volume = {1},
  pages = {3:1-3:11},
  file = {/home/stephen/Zotero/storage/ZAHZDSMS/Li - 2009 - A Bayesian Approach for Estimating and Replacing M.pdf},
  keywords = {Bayesian,CategoricalData,DataCleaning,Imputation,MissingData}
}

@book{mullerIntroductionMachineLearning2016,
  title = {Introduction to Machine Learning with {{Python}}: A Guide for Data Scientists},
  shorttitle = {Introduction to Machine Learning with {{Python}}},
  author = {M{\"u}ller, Andreas Christian and Guido, Sarah},
  year = {2016},
  edition = {First edition},
  publisher = {{O'Reilly}},
  address = {{Beijing Boston Farnham Sebastopol Tokyo}},
  isbn = {978-1-4493-6941-5},
  langid = {english},
  file = {/home/stephen/Zotero/storage/98A6U5V3/Andreas C. Müller, Sarah Guido - Introduction to Machine Learning with Python_ A Guide for Data Scientists-O’Reilly Media (2016).pdf;/home/stephen/Zotero/storage/NU8ELT6M/Müller and Guido - 2016 - Introduction to machine learning with Python a gu.pdf}
}

@inproceedings{pengDataPrepEDATaskCentric2021,
  title = {{{DataPrep}}.{{EDA}}: {{Task-Centric Exploratory Data Analysis}} for {{Statistical Modeling}} in {{Python}}},
  shorttitle = {{{DataPrep}}.{{EDA}}},
  booktitle = {Proceedings of the 2021 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Peng, Jinglin and Wu, Weiyuan and Lockhart, Brandon and Bian, Song and Yan, Jing Nathan and Xu, Linghao and Chi, Zhixuan and Rzeszotarski, Jeffrey M. and Wang, Jiannan},
  year = {2021},
  month = jun,
  pages = {2271--2280},
  publisher = {{ACM}},
  address = {{Virtual Event China}},
  doi = {10.1145/3448016.3457330},
  urldate = {2023-09-20},
  isbn = {978-1-4503-8343-1},
  langid = {english},
  file = {/home/stephen/Zotero/storage/KACA343Q/DataPrepEDA Task Centric Exploratory Data Analysis for Statistical Modeling in Python.pdf},
  keywords = {BigData,DistributedData,EDA,Profiling,Python}
}

@book{thakurApproachingAlmostAny2020,
  title = {Approaching ({{Almost}}) {{Any Machine Learning Problem}}},
  author = {THAKUR, {\relax ABHISHEK}},
  year = {2020},
  publisher = {{ABHISHEK THAKUR}},
  address = {{S.l.}},
  isbn = {978-93-90274-43-7},
  langid = {english},
  annotation = {OCLC: 1368347003},
  file = {/home/stephen/Zotero/storage/A35T5GMT/THAKUR - 2020 - APPROACHING (ALMOST) ANY MACHINE LEARNING PROBLEM.pdf}
}

@book{weissIntroductoryStatistics2017,
  title = {Introductory Statistics},
  author = {Weiss, Neil A.},
  year = {2017},
  edition = {10th edition, global edition},
  publisher = {{Pearson}},
  address = {{Boston; Columbus; Indianapolis New York}},
  collaborator = {Weiss, Carol A.},
  isbn = {978-1-292-09972-9},
  langid = {english},
  file = {/home/stephen/Zotero/storage/XF5DEB94/Weiss - 2017 - Introductory statistics.pdf}
}

@inproceedings{yangUseCasePerformance2020,
  title = {Use {{Case}} and {{Performance Analyses}} for {{Missing Data Imputation Methods}} in {{Big Data Analytics}}},
  booktitle = {Proceedings of 2020 6th {{International Conference}} on {{Computing}} and {{Data Engineering}}},
  author = {Yang, Lan and Chiang, Jason Amaro},
  year = {2020},
  month = jan,
  pages = {107--111},
  publisher = {{ACM}},
  address = {{Sanya China}},
  doi = {10.1145/3379247.3379270},
  urldate = {2023-09-20},
  isbn = {978-1-4503-7673-0},
  langid = {english},
  file = {/home/stephen/Zotero/storage/57VBYQYU/Yang and Chiang - 2020 - Use Case and Performance Analyses for Missing Data.pdf},
  keywords = {Imputation,MissingData}
}

@book{zakiDataMiningMachine2020,
  title = {Data {{Mining}} and {{Machine Learning}}: {{Fundamental Concepts}} and {{Algorithms}}},
  shorttitle = {Data {{Mining}} and {{Machine Learning}}},
  author = {Zaki, Mohammed J. and Meira, Jr, Wagner},
  year = {2020},
  month = jan,
  edition = {2},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108564175},
  urldate = {2023-09-20},
  isbn = {978-1-108-56417-5 978-1-108-47398-9},
  file = {/home/stephen/Zotero/storage/4Z673CIN/Zaki and Meira, Jr - 2020 - Data Mining and Machine Learning Fundamental Conc.pdf}
}
